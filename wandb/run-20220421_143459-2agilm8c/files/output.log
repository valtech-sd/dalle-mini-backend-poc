

[34m[1mwandb[39m[22m: Downloading large artifact wzoooa1c:latest, 1672.79MB. 7 files... Done. 0:0:0
WARNING:dalle_mini.model.modeling:Some weights of the model checkpoint at /var/folders/22/mh3tzl8n7sdd9stq12996n0m0000gn/T/tmpb4x6om85 were not used when initializing DalleBart: {('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'RMSNorm_1', 'scale')}
- This IS expected if you are initializing DalleBart from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DalleBart from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:dalle_mini.model.modeling:Some weights of DalleBart were not initialized from the model checkpoint at /var/folders/22/mh3tzl8n7sdd9stq12996n0m0000gn/T/tmpb4x6om85 and are newly initialized: {('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'RMSNorm_3', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'RMSNorm_3', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'RMSNorm_3', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_5', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_4', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_6', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_5', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_1', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_10', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_8', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_1', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_8', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_3', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_2', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_10', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_2', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_4', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_11', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_6', 'RMSNorm_3', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'RMSNorm_1', 'scale'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_9', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_3', 'RMSNorm_1', 'scale'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_9', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_7', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_0', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_11', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'Core_remat_staticFlaxBartEncoderLayer_0', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'Core_remat_staticFlaxBartDecoderLayer_7', 'RMSNorm_3', 'scale')}
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/Users/max/Developer/future-studio-lab/dalle-playground/backend/app.py", line 67, in <module>
    model._params = replicate(model.params)
  File "/usr/local/lib/python3.9/site-packages/flax/jax_utils.py", line 56, in replicate
    return jax.device_put_replicated(tree, devices)
  File "/usr/local/lib/python3.9/site-packages/jax/_src/api.py", line 2786, in device_put_replicated
    return tree_map(_device_put_replicated, x)
  File "/usr/local/lib/python3.9/site-packages/jax/_src/tree_util.py", line 184, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.9/site-packages/jax/_src/tree_util.py", line 184, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.9/site-packages/jax/_src/api.py", line 2778, in _device_put_replicated
    core.raise_to_shaped(core.get_aval(x)))
  File "/usr/local/lib/python3.9/site-packages/jax/core.py", line 1093, in get_aval
    return concrete_aval(x)
  File "/usr/local/lib/python3.9/site-packages/jax/core.py", line 1085, in concrete_aval
    raise TypeError(f"Value {repr(x)} with type {type(x)} is not a valid JAX "
TypeError: Value ShapeDtypeStruct(shape=(1024, 1024), dtype=float32) with type <class 'jax._src.api.ShapeDtypeStruct'> is not a valid JAX type